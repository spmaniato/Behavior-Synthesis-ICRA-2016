% !TEX root = ../main.tex

\subsection{Multi-Paradigm Specification}

Specifying a robot task in a formal language can be a time consuming and error prone process.
It also requires an expert user, unless a natural language based approach is used \cite{Lignos2015AURO}. 
To alleviate these issues, we employ a multi-paradigm specification approach. 
We first observe that there are portions of the task specification $\mathcal{T}_\mathcal{S}$ that are going to be system-specific and portions that are going to be task-specific, such as the task's goals.
Intuitively, a user should only have to specify the goals without worrying about the internals of the robot and the software it is running.
\todo[inline, caption = {Mention offline system design earlier}]{This is important and needs to be mentioned earlier. Definitely in the intro. The fact that the system designer can put these things in place and users don't need to worry about them. (HKG)}
We can infer which actions are pertinent to a task and use the discrete abstraction $\mathcal{D}$ as the basis for automatically generating the portion of the formal specification that is related to the system itself.
Finally, the initial conditions are either specified by the user or detected at runtime.

Thus, referring to Problem \ref{SpecificationProblem}, we get the goals, $\mathcal{G}$, and initial conditions, $\mathcal{I}$, from the user.
The discrete abstraction, $\mathcal{D}$, is system-specific and we assume that it has been created a priori from expert developers, according to Section \ref{S:abstraction}.
We can now automatically generate the task specification $\mathcal{T}_\mathcal{S}$ in (the GR(1) fragment \cite{Bloem2012GR1} of) Linear Temporal Logic.
Since \textsc{ltl} is compositional, we can generate individual formulas and then conjunct them to get the full \textsc{ltl} specification.


\subsection{Specification of Actions and Control Mode Constraints}

Since the activation of capabilities is controlled by the system, the corresponding \textsc{ltl} formulas will be in $\varphi_s$ (c.f. Section \ref{S:GR1}).
Conversely, we do not control the outcome of activation; the environment does.
Therefore, the \textsc{ltl} formulas specifying the behavior of outcomes will be in $\varphi_e$.

\subsubsection{General Formulas}

We say that an activation proposition $\pi_y$, $y \in \{a, m\}$, is $\True$ when the corresponding primitive capability is being activated and $\False$ when it is not being activated\footnote{Note that this is in contrast to the work of Raman, et al. \cite{Vasu2013ICRA}, where, e.g., $\pi_{camera}$ being $\False$ stands for the corresponding primitive capability being \emph{deactivated}, i.e., turning a camera off.}.
Therefore, the system safety requirement \eqref{PropositionDeactivationFormula} dictates that all activation propositions $\pi_y \in \mathcal{Y}$ should turn $\False$ once an outcome has been returned.
Note that the left-hand side of formula \eqref{PropositionDeactivationFormula} is only $\True$ at those distinct time steps where an outcome was just returned.

\begin{equation}\label{PropositionDeactivationFormula}
	\bigwedge \limits_{o \in Out(y)} \LTLG \Big( \pi_y \wedge \LTLX \pi_y^o \Rightarrow \LTLX \lnot \pi_y \Big)
\end{equation}

The environment safety assumption \eqref{OutcomeMutexFormula} dictates that the outcomes, $\pi_y^o$, of the activation of any system capability are mutually exclusive (e.g., an action cannot both succeed and fail).
Formula \eqref{OutcomeMutexFormula} also allows for no outcome being $\True$.
\todo[inline, caption = {How to write Outcome MutEx formula (slugs)}]{Formula \eqref{OutcomeMutexFormula} requires the $\LTLX$ operators to synthesize properly (slugs), but intuitively, they shouldn't be there.}

\begin{equation}\label{OutcomeMutexFormula}
	\bigwedge \limits_{o \in Out(y)} \LTLG \Big( \LTLX \pi_y^o \Rightarrow \bigwedge \limits_{o^\prime \neq o} \LTLX \lnot \pi_y^{o^\prime} \Big)
\end{equation}

The environment safety assumption \eqref{ActionOutcomeConstraintFormula} constraints the value of outcomes.
Specifically, it dictates that, if an outcome is $\False$ and the corresponding capability is not being activated, then that outcome should remain $\False$.
It is a generalization of formula (4) in \cite{Vasu2013ICRA}.

\begin{equation}\label{ActionOutcomeConstraintFormula}
	\bigwedge \limits_{o \in Out(y)} \LTLG \Big( \lnot \pi_y^o \wedge \lnot \pi_y \Rightarrow \LTLX \lnot \pi_y^o \Big)
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Action-specific Formulas}

The following formulas encode the connection between the activation and the possible outcomes of the robot's actions, $a \in \mathcal{A}$.

%The environment safety assumptions \eqref{ActionOutcomeConstraintFormula} govern the value of outcomes in the next time step. 
%%Specifically, formula \eqref{ActionOutcomeConstraintsFormula3} says that if an outcome has been returned, and the corresponding action is re-activated, then any outcome can become $\True$. 
%Specifically, formula \eqref{ActionOutcomeConstraintFormula} dictates that, if an outcome is $\False$ and the corresponding action is not activated, then that outcome should remain $\False$.
%%This pair of formulas is a generalization of the ``fast-slow" formulas (3) and (4) in \cite{Vasu2013ICRA}.
%It is a generalization of formula (4) in \cite{Vasu2013ICRA}.

%\begin{subequations}
%	\label{ActionOutcomeConstraintsFormula}
%	\begin{align}
%		\LTLG& \Big( \bigvee \pi_a^o \wedge \pi_a \Rightarrow \bigvee \LTLX \pi_a^o \Big)\label{ActionOutcomeConstraintsFormula3}\\
%		\bigwedge \limits_{o \in Out(a)} \LTLG& \Big( \lnot \pi_a^o \wedge \lnot \pi_a \Rightarrow \LTLX \lnot \pi_a^o \Big)\label{ActionOutcomeConstraintsFormula4}
%	\end{align}
%\end{subequations}

%\begin{equation}\label{ActionOutcomeConstraintFormula}
%	\bigwedge \limits_{o \in Out(a)} \LTLG \Big( \lnot \pi_a^o \wedge \lnot \pi_a \Rightarrow \LTLX \lnot \pi_a^o \Big)
%\end{equation}

The environment safety assumption \eqref{ActionOutcomePersistenceFormula} dictates that the value of an outcome should not change if the corresponding action has not been activated again. 
In other words, outcomes persist through time.

\begin{equation}\label{ActionOutcomePersistenceFormula}
	\bigwedge \limits_{o \in Out(a)} \LTLG \Big( \pi_a^o \wedge \lnot \pi_a \Rightarrow \LTLX \pi_a^o \Big)
\end{equation}

The environment liveness assumption \eqref{ActionFairnessConditionsFormula} is a fairness condition.
%It states that, (always) eventually, either the activation of an action will return an outcome, \eqref{ActionFairnessConditionsFormula1}, or that the robot will ``change its mind", \eqref{ActionFairnessConditionsFormula2}.
%Formula \eqref{ActionFairnessConditionsFormula1} is a generalization of $\varphi_a^{completion}$ in \cite{Vasu2013ICRA}, whereas formula \eqref{ActionFairnessConditionsFormula2} is exactly the same as $\varphi_a^{change}$ in \cite{Vasu2013ICRA}, since it consists of activation propositions only.
It states that (always) eventually, the activation of an action will result in an outcome.
The disjunct $\lnot \pi_a$ is added in order to prevent situations where the environment loses the game due to the system never activating the action.
\todo[inline, caption = {Simplify fairness conditions explanation}]{Too technical. Explain the intuition - for each action we expect an outcome to become true unless the action is not called. (HKG)}

%\begin{subequations}
%	\begin{align}
%		\varphi_a^{return} = \Big( \pi_a \wedge \bigvee \LTLX \pi_a^o \Big) &\vee \Big( \lnot \pi_a \wedge \bigwedge \LTLX \lnot \pi_a^o \Big)\label{ActionFairnessConditionsFormula1}\\
%		\varphi_a^{change} = \big( \pi_a \wedge \LTLX \lnot \pi_a \big) &\vee \big( \lnot \pi_a \wedge \LTLX \pi_a \big)\label{ActionFairnessConditionsFormula2}\\
%		\LTLG \LTLF \big( \varphi_a^{return} &\vee \varphi_a^{change} \big)\label{ActionFairnessConditionsFormula}
%	\end{align}
%\end{subequations}

\begin{equation}\label{ActionFairnessConditionsFormula}
	\LTLG \LTLF \Big( \Big( \pi_a \wedge \bigvee \limits_{o \in Out(a)} \LTLX \pi_a^o \Big) \vee \lnot \pi_a \Big)
\end{equation}

The system safety requirement \eqref{PreconditionsFormula} constrains the activation of an action $a$ unless it preconditions, $Prec(a)$, are met.

\begin{equation}\label{PreconditionsFormula}
	\LTLG \Big( \bigvee \limits_{y \in Prec(a)} \lnot \pi_y^c \Rightarrow \lnot \pi_a \Big)
\end{equation}
where the superscript $c \in Out(y)$ stands for ``completion".

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Control Mode Formulas}

For brevity of notation, let $$\varphi_m = \pi_m \wedge \bigwedge_{m^\prime \neq m} \lnot \pi_{m^\prime}$$
Activating $\varphi_m$, as opposed to $\pi_m$, takes into account the mutual exclusion between control modes $m \in \mathcal{M}$.
Also let $$\varphi_\mathcal{M}^{none} = \bigwedge_{m \in \mathcal{M}} \lnot \pi_m,$$
where $\varphi_\mathcal{M}^{none}$ being $\True$ stands for not activating any control mode transitions, i.e., staying in the same control mode.

The system safety requirement \eqref{TransitionRelationFormula} encodes the BDI control mode transition system (Section \ref{S:CMActions}, Fig. \ref{Fig:ControlModeTS}) in \textsc{ltl}.

\begin{equation}\label{TransitionRelationFormula}
	\bigwedge \limits_{m \in \mathcal{M}} \LTLG \Big( \LTLX \pi_m^c \Rightarrow \bigvee \limits_{m^\prime \in Adj(m)} \LTLX \varphi_{m^\prime} \vee \LTLX \varphi_\mathcal{M}^{none} \Big)
\end{equation}

The environment safety assumption \eqref{TopologyMutexFormula} enforces mutual exclusion between the BDI control modes.
\todo[inline, caption = {How to write control mode MutEx formula (slugs)}]{Formula \eqref{TopologyMutexFormula} also requires the $\LTLX$ operators to synthesize properly (slugs), but intuitively, they shouldn't be there.}

\begin{equation}\label{TopologyMutexFormula}
	\bigwedge \limits_{m \in \mathcal{M}} \LTLG \Big( \LTLX \pi_m^c \Leftrightarrow \bigwedge \limits_{m^\prime \neq m} \LTLX \lnot \pi_{m^\prime}^c \Big)
\end{equation}

The environment safety assumption \eqref{SingleStepChangeFormula} governs how the active control mode can change (or not) in a single time step, in response to the activation of a control mode transition.

\begin{equation}\label{SingleStepChangeFormula}
	\bigwedge \limits_{m \in \mathcal{M}} \bigwedge \limits_{m^\prime \in Adj(m)} \LTLG \Big( \pi_m^c \wedge  \varphi_{m^\prime} \Rightarrow \big( \LTLX \pi_{m}^c \bigvee \limits_{o \in Out(m^\prime)} \LTLX \pi_{m^\prime}^o \big) \Big)
\end{equation}

%The environment safety assumptions \eqref{TopologyOutcomeConstraintFormula} constrain the outcomes control mode transitions.
%
%\begin{equation}\label{TopologyOutcomeConstraintFormula}
%	\bigwedge \limits_{m \in \mathcal{M}} \bigwedge \limits_{o \in Out(m)} \LTLG \Big( \lnot \pi_m^o \wedge \lnot \pi_m \Rightarrow \LTLX \lnot \pi_m^o \Big)
%\end{equation}

Similar to \eqref{ActionOutcomePersistenceFormula}, the environment safety assumption \eqref{TopologyOutcomePersistenceFormula} dictates that the value of the outcomes of control mode transitions must not change if no transition is being activated.

\begin{equation}\label{TopologyOutcomePersistenceFormula}
	\bigwedge \limits_{m \in \mathcal{M}} \bigwedge \limits_{o \in Out(m)} \LTLG \Big( \pi_m^o \wedge \varphi_\mathcal{M}^{none} \Rightarrow \LTLX \pi_m^o \Big)
\end{equation}

The environment liveness assumption \eqref{TopologyFairnessConditionsFormula} is the equivalent of the fairness condition \eqref{ActionFairnessConditionsFormula} for control modes.
A single formula suffices for mutually exclusive propositions \cite{Vasu2013ICRA}.

%\begin{subequations}
%	\begin{align}
%		\varphi_\mathcal{M}^{return} &= \bigvee \limits_{m \in \mathcal{M}} \Big( \varphi_m \wedge \bigvee \limits_{o \in Out(m)} \LTLX \pi_m^o \Big)\label{TopologyFairnessConditionsFormula1}\\
%		\varphi_\mathcal{M}^{change} &= \bigvee \limits_{m \in \mathcal{M}} \Big( \varphi_m \wedge \LTLX \lnot \varphi_m \Big)\label{TopologyFairnessConditionsFormula2}\\
%		\LTLG \LTLF & \big( \varphi_\mathcal{M}^{return} \vee \varphi_\mathcal{M}^{change} \vee \varphi_\mathcal{M}^{none} \big)\label{TopologyFairnessConditionsFormula}
%	\end{align}
%\end{subequations}

\begin{equation}\label{TopologyFairnessConditionsFormula}
	\LTLG \LTLF \Big( \bigvee \limits_{m \in \mathcal{M}} \Big( \varphi_m \wedge \bigvee \limits_{o \in Out(m)} \LTLX \pi_m^o \Big) \vee \varphi_\mathcal{M}^{none} \Big)
\end{equation}

This concludes the system-specific portion of $\mathcal{T_S}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Specification of Initial Conditions}

For each action, $a$, and control mode, $m$, in the initial conditions, $\mathcal{I}$, the completion proposition should be $\True$ in the environment initial conditions \eqref{EnvironmentInitialConditions}.
All other outcome propositions corresponding to those actions and control modes, as well as all outcome propositions corresponding to any other actions and control modes, should be $\False$.

\begin{equation}\label{EnvironmentInitialConditions}
	\varphi_i^e = \bigwedge \limits_{i \in \mathcal{I}} \Big( \pi_i^c \bigwedge \limits_{o \in Out(i)\backslash \{c\}} \lnot \pi_i^o \Big) \wedge \bigwedge \limits_{j \not\in \mathcal{I}} \bigwedge \limits_{o \in Out(j)} \lnot \pi_j^o
\end{equation}

Activation propositions are $\False$ regardless of whether that action or control mode is in the initial conditions or not \eqref{SystemInitialConditions}.
The intuitive reasons is that if we want something to be an initial condition, then the resulting plan should not activate it at the beginning of execution.

\begin{equation}\label{SystemInitialConditions}
	\varphi_i^s = \bigwedge \limits_{i \in \mathcal{I}} \lnot \pi_i \wedge \bigwedge \limits_{j \not \in \mathcal{I}} \lnot \pi_j
\end{equation}
\todo[inline, caption = {Where to state memory initial conditions ?}]{Do I move ICs to the end of the section and include memory props explicitly? Or leave them here, but state memory ICs along with ``infinite-to-finite" formulas?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Specification of Task Goals}\label{S:ltl-goals}

So far, we have handled the system-specific portion of $\mathcal{T_S}$ and the initial conditions, $\mathcal{I}$.
All that is left is the automatic generation of formulas from the user-specified task goals, $\mathcal{G}$.
Motivated by the DRC tasks, we will present \textsc{ltl} formulas that encode the accomplishment of each goal once.
However, \textsc{ltl} and its \textsc{gr(1)} fragment can naturally handle repeating tasks (e.g. patrolling).
In the context of graceful degradation, we could even combine the two.
For example, ``accomplish the goals $\mathcal{G}$ infinitely often, but if anything fails, abort".

The system initial condition \eqref{MemoryInitialCondition}, safety requirements \eqref{MemoryFormula} and \eqref{SMOutcomeFormulas}, and liveness requirement \eqref{SuccessLivenessFormula} are used to reason about the satisfaction of the system's goals, $g \in \mathcal{G}$, in a finite run (using the same \textsc{ltl} semantics as for infinite execution).
In this paradigm, we say that the run itself has outcomes too.
We denote them by $o \in Out(SM)$, since they will correspond to the outcomes of the synthesized plan, which will be a state machine (SM).
\todo[inline, caption = {Rename "SM outcome" propositions}]{I don't think the use of SM is good - these are behavior level propositions (outcomes, memory) but it does not matter that it is implemented as a state machine. it is a bit confusing. it is simply another set of propositions that are automatically added to the task formalism. (HKG)}
Note that the propositions corresponding to the run's outcomes, $\pi_{SM}^o$, are system, not environment, propositions.
We also introduce auxiliary system propositions, $\mu_g$, which will serve as memory (c.f. \cite{Vasu2012IROS}) of having accomplished each goal $g \in \mathcal{G}$.

\begin{equation}\label{MemoryInitialCondition}
	\bigwedge \limits_{g \in \mathcal{G}} \lnot \mu_g 
\end{equation}

%\begin{subequations}
%	\label{MemoryFormulas}
%	\begin{align}
%		\bigwedge \limits_{g \in \mathcal{G}} \LTLG& \Big( \LTLX \pi_g^c \Rightarrow \LTLX \mu_g \Big) \label{MemoryFormula1}\\
%		\bigwedge \limits_{g \in \mathcal{G}}\LTLG& \Big(  \mu_g \Rightarrow \LTLX \mu_g \Big) \label{MemoryFormula2}\\
%		\bigwedge \limits_{g \in \mathcal{G}}\LTLG& \Big(  \lnot \mu_g \wedge \LTLX \lnot \pi_g^c \Rightarrow \LTLX \lnot \mu_g \Big) \label{MemoryFormula3}
%\end{align}
%\end{subequations}

\begin{equation}\label{MemoryFormula}
	\bigwedge \limits_{g \in \mathcal{G}} \LTLG \big( \LTLX \pi_g^c \vee \mu_g \Leftrightarrow \LTLX \mu_g \big)
\end{equation}

\begin{subequations}
	\label{SMOutcomeFormulas}
	\begin{align}
		\LTLG \Big( \pi_{SM}^{c} \Leftrightarrow \bigwedge \limits_{g \in \mathcal{G}} \mu_g \Big) \label{SuccessfulOutcomeFormula}\\
		\LTLG \Big( \pi_{SM}^{f} \Leftrightarrow \bigvee \limits_{\pi \in \mathcal{Y}} \pi^f \Big) \label{FailedOutcomeFormula}\\
		\bigwedge \limits_{o \in Out(SM)} \LTLG \Big( \pi_{SM}^{o} \Rightarrow \LTLX \pi_{SM}^{o} \Big) \label{SMOutcomePersistenceFormula}
	\end{align}
\end{subequations}

\begin{equation}\label{SuccessLivenessFormula}
	\LTLG \LTLF \big( \bigvee \limits_{o \in Out(SM)} \pi_{SM}^{o} \big)
\end{equation}
The formulas above can be interpreted as: ``If nothing fails, then eventually accomplish each goal. Otherwise, abort". 

Formula \eqref{MemoryFormula} does not guarantee that the goals will be achieved in a specific order.
However, that is often desirable.
To this end, we can define the goals as an ordered set $\mathcal{G} = \{ g_1, g_2, \ldots, g_n \}$, where $g_i < g_j$ for $i<j$, and the relation $g_i < g_j$ means that goal $g_i$ has to be achieved before $g_j$.
With this definition, we can replace the safety requirement \eqref{MemoryFormula} with \eqref{GoalOrderFormula}, whenever strict goal order is desired.

\begin{equation}\label{GoalOrderFormula}
%	\bigwedge \limits_{i = 1}^n \LTLG \Big(  \lnot \mu_{g_{i-1}} \Rightarrow \LTLX \lnot \mu_{g_i} \Big), \; \mu_{g_0} \triangleq \True
	\bigwedge \limits_{i = 1}^n \LTLG \big( (\pi_{g_i} \wedge \LTLX \pi_{g_i}^c) \wedge \mu_{g_{i-1}} \vee \mu_{g_i} \Leftrightarrow \LTLX \mu_{g_i} \big),
\end{equation}
where $\mu_{g_0} \triangleq \True$.
Formula \eqref{GoalOrderFormula} forces the system to carry out goal $g_i$ after it has accomplished goal $g_{i-1}$.
It can still activate the capability corresponding to $\pi_{g_i}$ earlier, as necessitated by other parts of the task, but that will not count towards achievement of $g_i$ (indicated by $\mu_{g_i}$ being $\True$).

Finally, these auxiliary propositions (memory and outcomes of the run) are added to the system propositions: $$\mathcal{Y}^\prime = \mathcal{Y} \cup \bigcup \limits_{g \in \mathcal{G}} \mu_g \cup \bigcup \limits_{o \in Out(SM)} \pi_{SM}^o$$

%END